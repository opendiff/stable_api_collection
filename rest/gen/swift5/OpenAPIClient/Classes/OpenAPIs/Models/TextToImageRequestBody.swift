//
// TextToImageRequestBody.swift
//
// Generated by openapi-generator
// https://openapi-generator.tech
//

import Foundation
#if canImport(AnyCodable)
import AnyCodable
#endif

public struct TextToImageRequestBody: Codable, JSONEncodable, Hashable {

    public enum ClipGuidancePreset: String, Codable, CaseIterable {
        case fastBlue = "FAST_BLUE"
        case fastGreen = "FAST_GREEN"
        case _none = "NONE"
        case simple = "SIMPLE"
        case slow = "SLOW"
        case slower = "SLOWER"
        case slowest = "SLOWEST"
    }
    public enum Sampler: String, Codable, CaseIterable {
        case ddim = "DDIM"
        case ddpm = "DDPM"
        case kDpmpp2m = "K_DPMPP_2M"
        case kDpmpp2sAncestral = "K_DPMPP_2S_ANCESTRAL"
        case kDpm2 = "K_DPM_2"
        case kDpm2Ancestral = "K_DPM_2_ANCESTRAL"
        case kEuler = "K_EULER"
        case kEulerAncestral = "K_EULER_ANCESTRAL"
        case kHeun = "K_HEUN"
        case kLms = "K_LMS"
    }
    /** How strictly the diffusion process adheres to the prompt text (higher values keep your image closer to your prompt) */
    public var cfgScale: Double? = 7
    public var clipGuidancePreset: ClipGuidancePreset? = ._none
    /** Height of the image (note: `height * width` must be <= 1 Megapixel) */
    public var height: Int? = 512
    /** Which sampler to use for the diffusion process. If this value is omitted we'll automatically select an appropriate sampler for you. */
    public var sampler: Sampler?
    /** Number of images to generate */
    public var samples: Int? = 1
    /** Random noise seed (omit this option or use `0` for a random seed) */
    public var seed: Int?
    /** Number of diffusion steps to run */
    public var steps: Int? = 50
    public var textPrompts: [TextPrompt]
    /** Width of the image (note: `height * width` must be <= 1 Megapixel) */
    public var width: Int? = 512

    public init(cfgScale: Double? = 7, clipGuidancePreset: ClipGuidancePreset? = ._none, height: Int? = 512, sampler: Sampler? = nil, samples: Int? = 1, seed: Int? = nil, steps: Int? = 50, textPrompts: [TextPrompt], width: Int? = 512) {
        self.cfgScale = cfgScale
        self.clipGuidancePreset = clipGuidancePreset
        self.height = height
        self.sampler = sampler
        self.samples = samples
        self.seed = seed
        self.steps = steps
        self.textPrompts = textPrompts
        self.width = width
    }

    public enum CodingKeys: String, CodingKey, CaseIterable {
        case cfgScale = "cfg_scale"
        case clipGuidancePreset = "clip_guidance_preset"
        case height
        case sampler
        case samples
        case seed
        case steps
        case textPrompts = "text_prompts"
        case width
    }

    // Encodable protocol methods

    public func encode(to encoder: Encoder) throws {
        var container = encoder.container(keyedBy: CodingKeys.self)
        try container.encodeIfPresent(cfgScale, forKey: .cfgScale)
        try container.encodeIfPresent(clipGuidancePreset, forKey: .clipGuidancePreset)
        try container.encodeIfPresent(height, forKey: .height)
        try container.encodeIfPresent(sampler, forKey: .sampler)
        try container.encodeIfPresent(samples, forKey: .samples)
        try container.encodeIfPresent(seed, forKey: .seed)
        try container.encodeIfPresent(steps, forKey: .steps)
        try container.encode(textPrompts, forKey: .textPrompts)
        try container.encodeIfPresent(width, forKey: .width)
    }
}

